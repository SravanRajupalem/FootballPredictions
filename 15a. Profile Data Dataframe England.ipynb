{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import date\n",
    "import requests\n",
    "import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "from urllib.request import urlopen\n",
    "import glob\n",
    "import altair as alt\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def Filter(string, substr): \n",
    "        return [str for str in string if\n",
    "                any(sub in str for sub in substr)] \n",
    "    \n",
    "def NOTFilter(string, substr): \n",
    "    return [str for str in string if\n",
    "            any(sub not in str for sub in substr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fbref_league_history(league_id = [9,11,12,13,20], first_season = 2010):\n",
    "    history = []\n",
    "    for i in league_id:\n",
    "        comp_history_url = \"https://fbref.com/en/comps/\" + str(i) + \"/history\" \n",
    "        #print(comp_history_url)\n",
    "\n",
    "        r=requests.get(comp_history_url)\n",
    "        soup=BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "        find_seasons = soup.find_all(class_ = \"left\")\n",
    "\n",
    "        all_seasons_url = []\n",
    "        for k in range(0, len(find_seasons)):\n",
    "            if find_seasons[k].get('data-stat') == \"season\":\n",
    "                temp = \"https://fbref.com\" + find_seasons[k].find_all(\"a\")[0].attrs[\"href\"]\n",
    "                all_seasons_url.append(temp)\n",
    "\n",
    "        history.append(all_seasons_url)\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    # All histories in one array\n",
    "    history  = list(itertools.chain(*history))\n",
    "\n",
    "    seasons = list(map(lambda x: str(x)+\"-\"+str(x+1), np.arange(1950, first_season, 1)))\n",
    "    for i in seasons:\n",
    "        history = NOTFilter(history, [i])\n",
    "    del seasons\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting history for each league (England: 9 | Italy: 11 | Spain: 12 | France: 13 | Germany: 20)\n",
    "history_england = fbref_league_history(league_id = [9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fbref_team_url_history(league_history):\n",
    "    team_season_url = []\n",
    "    for league_season_url in league_history:\n",
    "        r=requests.get(league_season_url)\n",
    "        soup=BeautifulSoup(r.content, \"html.parser\")\n",
    "        teams = soup.find(\"table\").find_all(\"a\")\n",
    "        teams = list(map(lambda x: \"https://fbref.com\" + x[\"href\"], teams))\n",
    "        teams = Filter(teams, [\"/en/squads/\"])\n",
    "        team_season_url.append(teams)\n",
    "\n",
    "    # All histories in one array\n",
    "    team_season_url  = list(itertools.chain(*team_season_url))\n",
    "    return team_season_url\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Premier League (England) Seasons (England: 9 | Italy: 11 | Spain: 12 | France: 13 | Germany: 20)\n",
    "team_season_url_england = fbref_team_url_history(history_england)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fbref_player_url(team_season_url):\n",
    "    player_url = []\n",
    "    for turl in team_season_url:\n",
    "        r=requests.get(turl)\n",
    "        soup=BeautifulSoup(r.content, \"html.parser\")\n",
    "        soup.find(\"div\", {\"id\":\"all_stats_standard\"})\n",
    "        players = soup.find(\"tbody\").find_all(\"a\")\n",
    "        players = list(map(lambda x: x[\"href\"], players))\n",
    "        players = Filter(players, [\"/en/players/\"])\n",
    "        players = NOTFilter(players, [\"matchlogs\"])\n",
    "        player_url.append(list(map(lambda x: \"https://fbref.com\" + x, players)))\n",
    "        time.sleep(0.01)\n",
    "    player_url  = list(itertools.chain(*player_url))\n",
    "    return player_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting players urls for England\n",
    "player_url_england = fbref_player_url(team_season_url_england)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6626"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(player_url_england)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fbref_player_info(player_url):\n",
    "    player_info = []\n",
    "    for completed, i in enumerate(player_url):\n",
    "\n",
    "        # PlayerId\n",
    "        playerId = i.replace(\"https://fbref.com/en/players/\", \"\").split(\"/\")[0]\n",
    "\n",
    "        # Request\n",
    "        r=requests.get(i)\n",
    "        soup=BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "        # Meta\n",
    "        meta = soup.find(\"div\", {\"id\":\"meta\"})\n",
    "\n",
    "        # Player Name\n",
    "        playerName = soup.find(\"h1\").find(\"span\").get_text()\n",
    "        \n",
    "        # Nationality\n",
    "        birthplace = meta.find(\"span\", {\"itemprop\": \"birthPlace\"}).text.replace(\"\\n\", \"\").strip().split(\", \")\n",
    "        nationality = birthplace[len(birthplace)-1]\n",
    "        \n",
    "\n",
    "        # Player Photos\n",
    "        try:\n",
    "            photo = soup.find(\"div\", {\"class\":\"media-item\"}).find(\"img\").attrs[\"src\"]\n",
    "        except:\n",
    "            photo = np.nan\n",
    "\n",
    "\n",
    "        # Birth\n",
    "        try:\n",
    "            birth = meta.find(\"span\", {\"itemprop\": \"birthDate\"}).text.replace(\"\\n\", \"\").strip()\n",
    "            #soup.find(\"div\", {\"id\":\"meta\"}).find(\"span\", {\"id\":\"necro-birth\"})['data-birth']\n",
    "        except:\n",
    "            birth = np.nan\n",
    "\n",
    "        # Height\n",
    "        try:\n",
    "            height = meta.find(\"span\", {\"itemprop\":\"height\"}).text.replace(\"cm\", \"\")\n",
    "        except:\n",
    "            height = np.nan\n",
    "\n",
    "        # Weight\n",
    "        try:\n",
    "            weight = soup.find(\"div\", {\"id\":\"meta\"}).find(\"span\", {\"itemprop\":\"weight\"}).text.replace(\"kg\", \"\")\n",
    "        except :\n",
    "            weight = np.nan\n",
    "\n",
    "\n",
    "        detail = meta.find_all(\"p\")\n",
    "\n",
    "        # Player Full Name\n",
    "        if len(Filter([detail[0].text], [\"Position\", \"Club\", \"Born\", \"National Team\", \"Citizenship\"])) > 0:\n",
    "                playerFullName = np.nan\n",
    "        else:\n",
    "            playerFullName = detail[0].get_text()\n",
    "\n",
    "        # Position & Footed\n",
    "        fp = list(map(lambda x: str(x), detail))\n",
    "        position = Filter(fp, [\"Position\"])\n",
    "        footed = Filter(fp, [\"Footed\"])\n",
    "        if len(position) > 0:\n",
    "            position = position[0].split(\"<strong>\")[1].replace(\"Position:</strong>\",\"\").replace(\"\\n\", \"\").replace(\"<p>\", \"\").replace(\"</p>\", \"\").replace(\"\\xa0\", \"\").replace(\"â–ª\", \"\").split(\"<span\")[0].strip()\n",
    "        else:\n",
    "            position = np.nan\n",
    "\n",
    "        if len(footed) > 0:\n",
    "            footed = footed[0].split(\"<strong>Footed:</strong>\")[1].split(\"<span\")[0].strip().replace(\"</p>\", \"\").upper()\n",
    "            footed = footed.split(\"% \")\n",
    "            if len(footed) > 1:\n",
    "                foot = footed[1]\n",
    "                foot_ability = int(footed[0]) \n",
    "            else:\n",
    "                foot = footed[0]\n",
    "                foot_ability = 100\n",
    "        else:\n",
    "            foot = np.nan\n",
    "            foot_ability = np.nan\n",
    "\n",
    "        # International Reputation\n",
    "        try:\n",
    "            ir = soup.find(\"ul\", {\"id\":\"bling\"}).find_all(\"a\")\n",
    "            ir = list(map(lambda x: x.text.strip(), ir))\n",
    "            ir = '||'.join(map(str, ir))  # While the variable will be made || should be separated with\n",
    "        except:\n",
    "            ir = np.nan\n",
    "            \n",
    "        #Social Media\n",
    "        sm = Filter(list(map(lambda x: x[\"href\"], meta.find_all(\"a\", href = True))), [\"twitter\", \"instagram\"])\n",
    "        try:\n",
    "            tw = Filter(sm, [\"twitter\"])[0]\n",
    "        except:\n",
    "            tw = np.nan\n",
    "        try:\n",
    "            ins = Filter(sm, [\"instagram\"])[0]\n",
    "        except:\n",
    "            ins = np.nan\n",
    "\n",
    "        # Data Frame\n",
    "        temp = pd.DataFrame({\n",
    "            \"FBRefId\":[playerId],\n",
    "            \"PlayerName\":[playerName],\n",
    "            \"PlayerFullName\":[playerFullName],\n",
    "            \"Nationality\":[nationality],\n",
    "            \"Photo\":[photo],\n",
    "            \"Birth\":[birth],\n",
    "            \"Height\":[height],\n",
    "            \"Weight\":[weight],\n",
    "            \"Position\":[position],\n",
    "            \"Foot\":[foot],\n",
    "            \"FootAbility\":[foot_ability],\n",
    "            \"InternationalReputation\":[ir],\n",
    "            \"PlayerUrl\":[i],\n",
    "            \"Twitter\":[tw],\n",
    "            \"Instagram\":[ins]\n",
    "        })    \n",
    "\n",
    "        temp[\"PlayerFullName\"] = np.where(temp.PlayerFullName.isnull(), temp.PlayerName, temp.PlayerFullName)\n",
    "\n",
    "        player_info.append(temp)\n",
    "\n",
    "        # Print Message\n",
    "        sys.stdout.write(\"\\r{0} players have just scraped from FBRef!\".format(completed+1))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        # System Sleep\n",
    "        time.sleep(0.01) \n",
    "\n",
    "    # Write Player Info\n",
    "    player_info = pd.concat(player_info)\n",
    "    \n",
    "    return player_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6626 players have just scraped from FBRef!"
     ]
    }
   ],
   "source": [
    "# Getting players info for England (England: 9 | Italy: 11 | Spain: 12 | France: 13 | Germany: 20)\n",
    "player_info_england = fbref_player_info(player_url_england)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Player Info for all countries\n",
    "\n",
    "pd.DataFrame(player_info_england).to_csv('/Volumes/GoogleDrive/.shortcut-targets-by-id/1KUGn_35OjAoOP2puz6yG-2g_8LBxvDG_/SIADS 697 - Capstone/Dataframes/player_data_df_england.csv', index=False)\n",
    "\n",
    "# pd.DataFrame(df_39_columns_1).to_csv('/Users/vruiz.CDS/Downloads/Dataframes/consolidated_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
