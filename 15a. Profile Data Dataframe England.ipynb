{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import date\n",
    "import requests\n",
    "import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "from urllib.request import urlopen\n",
    "import glob\n",
    "import altair as alt\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def Filter(string, substr): \n",
    "        return [str for str in string if\n",
    "                any(sub in str for sub in substr)] \n",
    "    \n",
    "def NOTFilter(string, substr): \n",
    "    return [str for str in string if\n",
    "            any(sub not in str for sub in substr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fbref_league_history(league_id = [9,11,12,13,20], first_season = 2010):\n",
    "    history = []\n",
    "    for i in league_id:\n",
    "        comp_history_url = \"https://fbref.com/en/comps/\" + str(i) + \"/history\" \n",
    "        #print(comp_history_url)\n",
    "\n",
    "        r=requests.get(comp_history_url)\n",
    "        soup=BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "        find_seasons = soup.find_all(class_ = \"left\")\n",
    "\n",
    "        all_seasons_url = []\n",
    "        for k in range(0, len(find_seasons)):\n",
    "            if find_seasons[k].get('data-stat') == \"season\":\n",
    "                temp = \"https://fbref.com\" + find_seasons[k].find_all(\"a\")[0].attrs[\"href\"]\n",
    "                all_seasons_url.append(temp)\n",
    "\n",
    "        history.append(all_seasons_url)\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    # All histories in one array\n",
    "    history  = list(itertools.chain(*history))\n",
    "\n",
    "    seasons = list(map(lambda x: str(x)+\"-\"+str(x+1), np.arange(1950, first_season, 1)))\n",
    "    for i in seasons:\n",
    "        history = NOTFilter(history, [i])\n",
    "    del seasons\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting history for each league (England: 9 | Italy: 11 | Spain: 12 | France: 13 | Germany: 20)\n",
    "history_england = fbref_league_history(league_id = [9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_italy = fbref_league_history(league_id = [11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_spain = fbref_league_history(league_id = [12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_france = fbref_league_history(league_id = [13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_germany = fbref_league_history(league_id = [20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fbref_team_url_history(league_history):\n",
    "    team_season_url = []\n",
    "    for league_season_url in league_history:\n",
    "        r=requests.get(league_season_url)\n",
    "        soup=BeautifulSoup(r.content, \"html.parser\")\n",
    "        teams = soup.find(\"table\").find_all(\"a\")\n",
    "        teams = list(map(lambda x: \"https://fbref.com\" + x[\"href\"], teams))\n",
    "        teams = Filter(teams, [\"/en/squads/\"])\n",
    "        team_season_url.append(teams)\n",
    "\n",
    "    # All histories in one array\n",
    "    team_season_url  = list(itertools.chain(*team_season_url))\n",
    "    return team_season_url\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Premier League (England) Seasons (England: 9 | Italy: 11 | Spain: 12 | France: 13 | Germany: 20)\n",
    "team_season_url_england = fbref_team_url_history(history_england)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serie A (Italy) Seasons (England: 9 | Italy: 11 | Spain: 12 | France: 13 | Germany: 20)\n",
    "team_season_url_italy = fbref_team_url_history(history_italy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La Liga (Spain) Seasons (England: 9 | Italy: 11 | Spain: 12 | France: 13 | Germany: 20)\n",
    "team_season_url_spain = fbref_team_url_history(history_spain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ligue 1 (France) Seasons (England: 9 | Italy: 11 | Spain: 12 | France: 13 | Germany: 20)\n",
    "team_season_url_france = fbref_team_url_history(history_france)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bundesliga (Germany) Seasons (England: 9 | Italy: 11 | Spain: 12 | France: 13 | Germany: 20)\n",
    "team_season_url_germany = fbref_team_url_history(history_germany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fbref_player_url(team_season_url):\n",
    "    player_url = []\n",
    "    for turl in team_season_url:\n",
    "        r=requests.get(turl)\n",
    "        soup=BeautifulSoup(r.content, \"html.parser\")\n",
    "        soup.find(\"div\", {\"id\":\"all_stats_standard\"})\n",
    "        players = soup.find(\"tbody\").find_all(\"a\")\n",
    "        players = list(map(lambda x: x[\"href\"], players))\n",
    "        players = Filter(players, [\"/en/players/\"])\n",
    "        players = NOTFilter(players, [\"matchlogs\"])\n",
    "        player_url.append(list(map(lambda x: \"https://fbref.com\" + x, players)))\n",
    "        time.sleep(0.01)\n",
    "    player_url  = list(itertools.chain(*player_url))\n",
    "    return player_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting players urls for England (England: 9 | Italy: 11 | Spain: 12 | France: 13 | Germany: 20)\n",
    "player_url_england = fbref_player_url(team_season_url_england)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-a560255c8f1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Getting players urls for Italy (England: 9 | Italy: 11 | Spain: 12 | France: 13 | Germany: 20)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplayer_url_italy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfbref_player_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteam_season_url_italy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-fe17da2c3a5b>\u001b[0m in \u001b[0;36mfbref_player_url\u001b[0;34m(team_season_url)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mturl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mteam_season_url\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mturl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0msoup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"html.parser\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"div\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"all_stats_standard\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mplayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tbody\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m                 \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m_feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m         \u001b[0;31m# Close out any unfinished strings and close all the open tags.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/bs4/builder/_htmlparser.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m             \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m             \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mHTMLParseError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/html/parser.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \"\"\"\n\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoahead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/html/parser.py\u001b[0m in \u001b[0;36mgoahead\u001b[0;34m(self, end)\u001b[0m\n\u001b[1;32m    163\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munescape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdatepos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/bs4/builder/_htmlparser.py\u001b[0m in \u001b[0;36mhandle_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhandle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;34m\"\"\"Handle some textual data that shows up between tags.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhandle_charref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Getting players urls for Italy (England: 9 | Italy: 11 | Spain: 12 | France: 13 | Germany: 20)\n",
    "player_url_italy = fbref_player_url(team_season_url_italy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting players urls for Spain (England: 9 | Italy: 11 | Spain: 12 | France: 13 | Germany: 20)\n",
    "player_url_spain = fbref_player_url(team_season_url_spain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting players urls for France (England: 9 | Italy: 11 | Spain: 12 | France: 13 | Germany: 20)\n",
    "player_url_france = fbref_player_url(team_season_url_france)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting players urls for Germany (England: 9 | Italy: 11 | Spain: 12 | France: 13 | Germany: 20)\n",
    "player_url_germany = fbref_player_url(team_season_url_germany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "https://fbref.com/en/players/1ecb65be/Theo-Walcott           14\n",
       "https://fbref.com/en/players/01226327/Ryan-Bertrand          13\n",
       "https://fbref.com/en/players/86dd77d1/Kyle-Walker            13\n",
       "https://fbref.com/en/players/2f90f6b8/James-Milner           13\n",
       "https://fbref.com/en/players/2ff964a0/Aaron-Lennon           13\n",
       "                                                             ..\n",
       "https://fbref.com/en/players/b3576b7c/Erwin-Mulder            1\n",
       "https://fbref.com/en/players/ed2b33cb/Yuri-Zhirkov            1\n",
       "https://fbref.com/en/players/9fc0f253/Matt-Miazga             1\n",
       "https://fbref.com/en/players/05380aa0/Richard-Kingson         1\n",
       "https://fbref.com/en/players/0f933743/Francisco-Sierralta     1\n",
       "Name: 0, Length: 2450, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(player_url_england)\n",
    "df[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7179"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(player_url_england)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fbref_player_info(player_url):\n",
    "    player_info = []\n",
    "    for completed, i in enumerate(player_url):\n",
    "\n",
    "        # PlayerId\n",
    "        playerId = i.replace(\"https://fbref.com/en/players/\", \"\").split(\"/\")[0]\n",
    "\n",
    "        # Request\n",
    "        r=requests.get(i)\n",
    "        soup=BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "        # Meta\n",
    "        meta = soup.find(\"div\", {\"id\":\"meta\"})\n",
    "\n",
    "        # Player Name\n",
    "        playerName = soup.find(\"h1\").find(\"span\").get_text()\n",
    "        \n",
    "        # Nationality\n",
    "        birthplace = meta.find(\"span\", {\"itemprop\": \"birthPlace\"}).text.replace(\"\\n\", \"\").strip().split(\", \")\n",
    "        nationality = birthplace[len(birthplace)-1]\n",
    "        \n",
    "\n",
    "        # Player Photos\n",
    "        try:\n",
    "            photo = soup.find(\"div\", {\"class\":\"media-item\"}).find(\"img\").attrs[\"src\"]\n",
    "        except:\n",
    "            photo = np.nan\n",
    "\n",
    "\n",
    "        # Birth\n",
    "        try:\n",
    "            birth = meta.find(\"span\", {\"itemprop\": \"birthDate\"}).text.replace(\"\\n\", \"\").strip()\n",
    "            #soup.find(\"div\", {\"id\":\"meta\"}).find(\"span\", {\"id\":\"necro-birth\"})['data-birth']\n",
    "        except:\n",
    "            birth = np.nan\n",
    "\n",
    "        # Height\n",
    "        try:\n",
    "            height = meta.find(\"span\", {\"itemprop\":\"height\"}).text.replace(\"cm\", \"\")\n",
    "        except:\n",
    "            height = np.nan\n",
    "\n",
    "        # Weight\n",
    "        try:\n",
    "            weight = soup.find(\"div\", {\"id\":\"meta\"}).find(\"span\", {\"itemprop\":\"weight\"}).text.replace(\"kg\", \"\")\n",
    "        except :\n",
    "            weight = np.nan\n",
    "\n",
    "\n",
    "        detail = meta.find_all(\"p\")\n",
    "\n",
    "        # Player Full Name\n",
    "        if len(Filter([detail[0].text], [\"Position\", \"Club\", \"Born\", \"National Team\", \"Citizenship\"])) > 0:\n",
    "                playerFullName = np.nan\n",
    "        else:\n",
    "            playerFullName = detail[0].get_text()\n",
    "\n",
    "        # Position & Footed\n",
    "        fp = list(map(lambda x: str(x), detail))\n",
    "        position = Filter(fp, [\"Position\"])\n",
    "        footed = Filter(fp, [\"Footed\"])\n",
    "        if len(position) > 0:\n",
    "            position = position[0].split(\"<strong>\")[1].replace(\"Position:</strong>\",\"\").replace(\"\\n\", \"\").replace(\"<p>\", \"\").replace(\"</p>\", \"\").replace(\"\\xa0\", \"\").replace(\"▪\", \"\").split(\"<span\")[0].strip()\n",
    "        else:\n",
    "            position = np.nan\n",
    "\n",
    "        if len(footed) > 0:\n",
    "            footed = footed[0].split(\"<strong>Footed:</strong>\")[1].split(\"<span\")[0].strip().replace(\"</p>\", \"\").upper()\n",
    "            footed = footed.split(\"% \")\n",
    "            if len(footed) > 1:\n",
    "                foot = footed[1]\n",
    "                foot_ability = int(footed[0]) \n",
    "            else:\n",
    "                foot = footed[0]\n",
    "                foot_ability = 100\n",
    "        else:\n",
    "            foot = np.nan\n",
    "            foot_ability = np.nan\n",
    "\n",
    "        # International Reputation\n",
    "        try:\n",
    "            ir = soup.find(\"ul\", {\"id\":\"bling\"}).find_all(\"a\")\n",
    "            ir = list(map(lambda x: x.text.strip(), ir))\n",
    "            ir = '||'.join(map(str, ir))  # While the variable will be made || should be separated with\n",
    "        except:\n",
    "            ir = np.nan\n",
    "            \n",
    "        #Social Media\n",
    "        sm = Filter(list(map(lambda x: x[\"href\"], meta.find_all(\"a\", href = True))), [\"twitter\", \"instagram\"])\n",
    "        try:\n",
    "            tw = Filter(sm, [\"twitter\"])[0]\n",
    "        except:\n",
    "            tw = np.nan\n",
    "        try:\n",
    "            ins = Filter(sm, [\"instagram\"])[0]\n",
    "        except:\n",
    "            ins = np.nan\n",
    "\n",
    "        # Data Frame\n",
    "        temp = pd.DataFrame({\n",
    "            \"FBRefId\":[playerId],\n",
    "            \"PlayerName\":[playerName],\n",
    "            \"PlayerFullName\":[playerFullName],\n",
    "            \"Nationality\":[nationality],\n",
    "            \"Photo\":[photo],\n",
    "            \"Birth\":[birth],\n",
    "            \"Height\":[height],\n",
    "            \"Weight\":[weight],\n",
    "            \"Position\":[position],\n",
    "            \"Foot\":[foot],\n",
    "            \"FootAbility\":[foot_ability],\n",
    "            \"InternationalReputation\":[ir],\n",
    "            \"PlayerUrl\":[i],\n",
    "            \"Twitter\":[tw],\n",
    "            \"Instagram\":[ins]\n",
    "        })    \n",
    "\n",
    "        temp[\"PlayerFullName\"] = np.where(temp.PlayerFullName.isnull(), temp.PlayerName, temp.PlayerFullName)\n",
    "\n",
    "        player_info.append(temp)\n",
    "\n",
    "        # Print Message\n",
    "        sys.stdout.write(\"\\r{0} players have just scraped from FBRef!\".format(completed+1))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        # System Sleep\n",
    "        time.sleep(0.01) \n",
    "\n",
    "    # Write Player Info\n",
    "    player_info = pd.concat(player_info)\n",
    "    \n",
    "    return player_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264 players have just scraped from FBRef!"
     ]
    }
   ],
   "source": [
    "# Getting players info for England (England: 9 | Italy: 11 | Spain: 12 | France: 13 | Germany: 20)\n",
    "player_info_england = fbref_player_info(player_url_england)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Player Info for all countries\n",
    "\n",
    "pd.DataFrame(player_info_england).to_csv('/Volumes/GoogleDrive/.shortcut-targets-by-id/1KUGn_35OjAoOP2puz6yG-2g_8LBxvDG_/SIADS 697 - Capstone/Dataframes/player_data_df_england.csv', index=False)\n",
    "pd.DataFrame(player_info_italy).to_csv('/Volumes/GoogleDrive/.shortcut-targets-by-id/1KUGn_35OjAoOP2puz6yG-2g_8LBxvDG_/SIADS 697 - Capstone/Dataframes/player_data_df_italy.csv', index=False)\n",
    "pd.DataFrame(player_info_spain).to_csv('/Volumes/GoogleDrive/.shortcut-targets-by-id/1KUGn_35OjAoOP2puz6yG-2g_8LBxvDG_/SIADS 697 - Capstone/Dataframes/player_data_df_spain.csv', index=False)\n",
    "pd.DataFrame(player_info_france).to_csv('/Volumes/GoogleDrive/.shortcut-targets-by-id/1KUGn_35OjAoOP2puz6yG-2g_8LBxvDG_/SIADS 697 - Capstone/Dataframes/player_data_df_france.csv', index=False)\n",
    "pd.DataFrame(player_info_germany).to_csv('/Volumes/GoogleDrive/.shortcut-targets-by-id/1KUGn_35OjAoOP2puz6yG-2g_8LBxvDG_/SIADS 697 - Capstone/Dataframes/player_data_df_germany.csv', index=False)\n",
    "\n",
    "\n",
    "# pd.DataFrame(df_39_columns_1).to_csv('/Users/vruiz.CDS/Downloads/Dataframes/consolidated_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
